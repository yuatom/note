# 进程调度
相关定义：
`非抢占式多任务`，cooperative multitasking，除非进程自己主动停止运行，否则它会一直执行。
`抢占式多任务`，preemptive multitasking，由调度程序来决定什么时候停止一个进程的运行，以便其他进程能够得到执行机会。这个强制将程序挂起的动作就叫做抢占。
`进程的时间片`，timeslice，进程在被抢占之前能够运行的时间。
`让步`，yielding，进程主动挂起自己的操作。

##1.调度策略
###1.1.进程类型
I/O消耗性，大部分时间用来提交I/O请求或等待I/O请求。这些进程经常处于运行状态，但是运行的时间都比较短。这里的I/O是指任何类型的可阻塞资源，比如键盘输入、网络I/O等。
处理消耗性，时间大多都用在执行代码上。对于这里处理器消耗型的进程，调度策略往往是尽量降低它们的调度频率，而延长其运行时间。
调度策略通常要在两个矛盾的目标中间寻找平衡：进程响应迅速（响应时间短）和最大系统利用率（高吞吐量）。Unix系统的调度程序更倾向于I/O消耗型程序，以提供更好的程序响应速度。

###1.2.进程优先级
相同优先级的进程按轮转方式进行调度。
调度程序总是选择时间片未用尽而且优先级最高的程序运行。
####1.2.1.nice值
nice值表示对系统中其他程序的友好度，取值从-20到+19，值越大意味着更低的优先级。
不同的Unix系统由于调度算法不同，因此nice值的运用方式有所差异。Linux中nice值表示时间片的比例。

####1.2.2.实时优先级
取值范围是0到99，实时优先级数值越高意味着进程优先级越高。任何实时进程的优先级都高于普通的进程。
该值是可配置，而不是由算法策略自动算出的。

###1.3时间片
时间片是一个数值，表示进程在被抢占前所能持续运行的时间。
调度策略必须规定一个合适的默认时间片。默认时间片过长会导致系统对交互的响应表现欠佳，让人觉得系统无法并发执行应用程序；时间片太短会增大进程切换带来的处理器耗时。
I/O消耗型进程不需要太长的时间片，处理器消耗型进程则希望越长越好。
为了能获得更好的系统交互表现，大多数系统的默认时间片都很短。但是Linux的CFS调度器并没有直接给进程分配时间片，而是将**处理器的使用比**划分给了进程，使得进程所获得的处理器时间其实是和系统负载密切相关的。这个比例还有进一步受进程nice值影响，该值作为权重调整进程处理器时间使用比。更高nice的进程将被赋予低权重，从而失去一部分的处理器使用比。
在多数系统中，是否将一个进程立刻投入运行，完全由进程优先级和是否有时间片决定的。但在Linux中的CFS调度器，其抢占时机**取决于可运行程序消耗了多少处理器使用比**。如果小号的使用比比当前进程小，则新进程立刻投入运行，抢占当前进程。否则将推迟其运行。

##2.Linux调度算法
Linux进程调度是以模块方式提供的，可以针对不同类型的进程选择不同的算法。
调度器类（scheduler classes）允许多种不同的可动态添加的调度算法并存，每个调度器都有一个优先级。基础的调度器会按照优先级顺序遍历调度类。

###2.1.Unix进程调度
具有更高优先级的进程将运行得更频繁，而且也会被赋予更多的时间。Unix系统中，优先级以nice值形式输出给用户空间。
由于只是简单地按照nice值决定优先级，会导致以下问题：
>* 如果简单地将nice值映射到时间片，两个优先级相同但类型不同的进程，将拥有相同的时间片，假设一个是IO消耗型，一个是处理器消耗型，将被分配相同的运行频率和运行时间，这明显不太合理。IO消耗型需要更高的运行频率更低的运行时间，但处理器消耗型正好相反；
>* 同样和将nice值映射到时间片有关系。如果两个进程的nice值分别是0和1，分配到的时间片分别是100ms和95ms，这样两者的时间几乎相同，而如果两个进程的nice值分别是18和19，分配的时间片分别是10ms和5ms，前者是后者两倍。在调整nice值的时候，对进程时间片的影响不太取决于改变的值，而更大地取决于该进程的初始nice值；
>* 如果将nice值映射到时间片，那么每一个单位的时间片必须是在内核的测试范围内。在多数操作系统中要满足该要求意味着时间片是定时器节拍的整数倍，那么在不同的机器上可能会有不同时间片；



###2.2.公平调度CFS
CFS调度理念：进程调度的效果应如同系统具备一个理想中的完美多任务处理器。每个进程将能获得1/n（n指可运行进程的数量）的处理器时间。同时可以给进程分配无限小的时间周期，在任何可测量周期内，n个进程中每个进程都有同样多的运行时间。假设有两个运行进程，标准的Unix进程会先运行其中一个5ms再运行另一个5ms，每个进程在运行的时候会独占100%的处理器；而在理想的情况下，完美多任务处理模型希望能在10ms内同时运行两个进程，每个占50%的处理器。但由于无法在一个处理器上真的同时运行多个进程，所以理想模型无法实现。而且如果时间周期太小，在进程切换上会消耗很多资源，同时还有影响到缓存的效率。

CFS允许每个进程运行一段时间、循环轮转、选择运行最少的进程作为下一个运行进程，采用分配给进程一个处理器使用比重而不是分配时间片。CFS在所有可运行进程总数的基础上计算出一个进程应该运行多久，而不是依靠nice值来计算时间片。nice值会映射到计算**进程所分配的处理器运行比**的权重，且该权重与nice值大小成反比。

目标延迟：CFS为完美多任务中的无限小调度周期的近似值。越小的调度周期能有越好的交互性及更接近完美多任务，但会有更高的切换代价及更差的系统总吞吐能力。
当可运行任务趋于无限时，进程所获得的处理器使用比和时间将趋近于0，因此需要引入每个进程获得的时间片底线，成为最小粒度。

##3.Linux调度实现
时间记账，进程选择，调度器入口，睡眠和唤醒。

###3.1.时间记账
所有的调度器都必须对进程运行时间做记账。
多数Unix系统中，会分配一个时间给每一个进程，当每次系统时钟节拍发生时，时间片都会被减少一个节拍周期，当一个进程的时间片被减少到0时，它就会被另一个时间片尚未减到0的可运行进程抢占。

####3.1.1.调度器实体结构
CFS没有时间片的概念，但也要维护每个进程运行的时间记账。
调度器实体结构会作为一个名为se的成员变量定义到task_struct中。

```c
struct sched_entity {
	struct load_weight	load;		/* for load-balancing */
	struct rb_node		run_node;
	struct list_head	group_node;
	unsigned int		on_rq;

	u64			exec_start;
	u64			sum_exec_runtime;
	u64			vruntime;    // 存放进程的虚拟运行时间
	u64		
		prev_sum_exec_runtime;

	u64			nr_migrations;

#ifdef CONFIG_SCHEDSTATS
	struct sched_statistics statistics;
#endif

#ifdef CONFIG_FAIR_GROUP_SCHED
	int			depth;
	struct sched_entity	*parent;
	/* rq on which this entity is (to be) queued: */
	struct cfs_rq		*cfs_rq;
	/* rq "owned" by this entity/group: */
	struct cfs_rq		*my_q;
#endif
```

####3.1.2.虚拟实时
`sched_entiy`中的vruntime成员用来存放进程的虚拟运行时间，该运行时间的计算是经过了所有可运行进程总数的标准化（或者说是呗加权的）。
虚拟时间是以ns为单位的，所以和定时器节拍无关。
理想的多任务处理中，相同优先级的进程的虚拟运行时间都是相同，会被分配到相等的处理器比，但是实际上处理器同一时间只能运行一个进程，所以CFS，使用vruntime来记录进程运行的时间已经该进程还需要再运行多久。

```c
/*
 * Update the current task's runtime statistics.
 */
static void update_curr(struct cfs_rq *cfs_rq)
{
	struct sched_entity *curr = cfs_rq->curr;
	u64 now = rq_clock_task(rq_of(cfs_rq));
	u64 delta_exec;

	if (unlikely(!curr))
		return;

    // 取出进程改成运行的时间
	delta_exec = now - curr->exec_start;
	if (unlikely((s64)delta_exec <= 0))
		return;

	curr->exec_start = now;

	schedstat_set(curr->statistics.exec_max,
		      max(delta_exec, curr->statistics.exec_max));

	curr->sum_exec_runtime += delta_exec;
	schedstat_add(cfs_rq, exec_clock, delta_exec);

    // 加权计算时间，并将时间加到当前调度器实体的vruntime中
	curr->vruntime += calc_delta_fair(delta_exec, curr);
	update_min_vruntime(cfs_rq);

	if (entity_is_task(curr)) {
		struct task_struct *curtask = task_of(curr);

		trace_sched_stat_runtime(curtask, delta_exec, curr->vruntime);
		cpuacct_charge(curtask, delta_exec);
		account_group_exec_runtime(curtask, delta_exec);
	}

	account_cfs_rq_runtime(cfs_rq, delta_exec);
}
``` 

###3.2.进程选择
CFS会平衡所有进程的vruntime，因此每一次进程切换都会选择vruntime最小的那个进程。
CFS选择红黑树来组织可运行进程队列，并利用该结构来迅速找到最小vruntime值的进程。

####3.2.1.选择下一个任务
保存进程队列的红黑树中，以进程的虚拟运行时间为节点键值。CFS选择下一个进程时，将取出红黑树中最左边的节点代表的进程。

```c
// 选择下一个进程的函数，定义在kernek/sched_fair.c中
static struct sched_entity *__pick_next_entity(struct sched_entity *se)
{
	struct rb_node *next = rb_next(&se->run_node);

	if (!next)
		return NULL;

	return rb_entry(next, struct sched_entity, run_node);
}
```
`__pick_next_entity()`本身并没有遍历树来找到最左边的节点，而是取出缓存在se中成员变量中的值。虽然红黑树查找起来的速度很快，但是更快的方式是将最左节点缓存起来。该函数的返回值是CFS调度选择的下一个进程。

####3.2.2.向树中加入进程
将进程加进红黑树中过程发生在进程变为可运行状态（被唤醒）或者是通过fork()出一个进程时。

```c

/*
 * MIGRATION
 *
 *	dequeue
 *	  update_curr()
 *	    update_min_vruntime()
 *	  vruntime -= min_vruntime
 *
 *	enqueue
 *	  update_curr()
 *	    update_min_vruntime()
 *	  vruntime += min_vruntime
 *
 * this way the vruntime transition between RQs is done when both
 * min_vruntime are up-to-date.
 *
 * WAKEUP (remote)
 *
 *	->migrate_task_rq_fair() (p->state == TASK_WAKING)
 *	  vruntime -= min_vruntime
 *
 *	enqueue
 *	  update_curr()
 *	    update_min_vruntime()
 *	  vruntime += min_vruntime
 *
 * this way we don't have the most up-to-date min_vruntime on the originating
 * CPU and an up-to-date min_vruntime on the destination CPU.
 */

static void
enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
{
	bool renorm = !(flags & ENQUEUE_WAKEUP) || (flags & ENQUEUE_MIGRATED);
	bool curr = cfs_rq->curr == se;

	/*
	 * If we're the current task, we must renormalise before calling
	 * update_curr().
	 */
	if (renorm && curr)
		se->vruntime += cfs_rq->min_vruntime;

	update_curr(cfs_rq);

	/*
	 * Otherwise, renormalise after, such that we're placed @ the current
	 * moment in time, instead of some random moment in the past. Being
	 * placed in the past could significantly boost this task to the
	 * fairness detriment of existing tasks.
	 */
	if (renorm && !curr)
		se->vruntime += cfs_rq->min_vruntime;

	enqueue_entity_load_avg(cfs_rq, se);
	account_entity_enqueue(cfs_rq, se);
	update_cfs_shares(cfs_rq);

	if (flags & ENQUEUE_WAKEUP) {
		place_entity(cfs_rq, se, 0);
		if (schedstat_enabled())
			enqueue_sleeper(cfs_rq, se);
	}

	check_schedstat_required();
	if (schedstat_enabled()) {
		update_stats_enqueue(cfs_rq, se);
		check_spread(cfs_rq, se);
	}
	if (!curr)
		__enqueue_entity(cfs_rq, se);
	se->on_rq = 1;

	if (cfs_rq->nr_running == 1) {
		list_add_leaf_cfs_rq(cfs_rq);
		check_enqueue_throttle(cfs_rq);
	}
}

/*
 * Enqueue an entity into the rb-tree:
 */
static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
{
	struct rb_node **link = &cfs_rq->tasks_timeline.rb_node;
	struct rb_node *parent = NULL;
	struct sched_entity *entry;
	int leftmost = 1;

	/*
	 * Find the right place in the rbtree:
	 */
	while (*link) {
		parent = *link;
		entry = rb_entry(parent, struct sched_entity, run_node);
		/*
		 * We dont care about collisions. Nodes with
		 * the same key stay together.
		 */
		if (entity_before(se, entry)) {
			link = &parent->rb_left;
		} else {
			link = &parent->rb_right;
			leftmost = 0;
		}
	}

	/*
	 * Maintain a cache of leftmost tree entries (it is frequently
	 * used):
	 */
	if (leftmost)
		cfs_rq->rb_leftmost = &se->run_node;

	rb_link_node(&se->run_node, parent, link);
	rb_insert_color(&se->run_node, &cfs_rq->tasks_timeline);
}
```

> entry = rb_entry(parent, struct sched_entity, run_node);
rb_entry(ptr, struct type, node)
以上rb_entry函数的参数表示，node是type结构体的一个成员，ptr是node的地址，该函数用来获取包含node的type的地址。

在enqueue_entity中更新运行时间和其他一些统计数据，然后调用__enqueue_entity()进行进程插入操作。
__enqueue_entity函数while循环遍历树来为当前的进程找一个合适匹配键值，如果要插入的键值小于当前遍历到的节点的键值，则左移，否则右移。如果一直左移，leftmost的值一直是1，则表示要插入的键值将会至于树的最左边。否则哪怕有一次右移，都说明不是树的最左边。如果leftmost=1，则改变缓存最左边节点的变量的值。之后调用rb_link_node函数来插入节点。rb_insert_color函数来更新树的自平衡。

####3.2.3.从树中删除进程
删除动作发生在进程堵塞（变为不可运行态）或者终止时（结束运行）

```c
static void
dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
{
	/*
	 * Update run-time statistics of the 'current'.
	 */
	update_curr(cfs_rq);
	dequeue_entity_load_avg(cfs_rq, se);

	if (schedstat_enabled())
		update_stats_dequeue(cfs_rq, se, flags);

	clear_buddies(cfs_rq, se);

	if (se != cfs_rq->curr)
		__dequeue_entity(cfs_rq, se);
	se->on_rq = 0;
	account_entity_dequeue(cfs_rq, se);

	/*
	 * Normalize the entity after updating the min_vruntime because the
	 * update can refer to the ->curr item and we need to reflect this
	 * movement in our normalized position.
	 */
	if (!(flags & DEQUEUE_SLEEP))
		se->vruntime -= cfs_rq->min_vruntime;

	/* return excess runtime on last dequeue */
	return_cfs_rq_runtime(cfs_rq);

	update_min_vruntime(cfs_rq);
	update_cfs_shares(cfs_rq);
}

static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
{
	if (cfs_rq->rb_leftmost == &se->run_node) {
		struct rb_node *next_node;
        
		next_node = rb_next(&se->run_node);
		cfs_rq->rb_leftmost = next_node;
	}

	rb_erase(&se->run_node, &cfs_rq->tasks_timeline);
}

```
__dequeue_entity函数中，调用rb_erase来完成删除节点的公告。如果要删除的进程是最左的进程，那么在删之前要调rb_next找到下一个最左节点。

###3.3.调度器入口
进程调度的主要入口点是schedule()（定义在kernel/sched.c中）。内核中其他部分通过schedule()来调用进程调度器，用来选择哪个进程可以运行以及何时将其投入运行。schedule()会找到一个最高优先级的调度类，然后该调度类在主机的可运行队列中选择下一个该运行的进程。在schedule()中会调用pick_next_task()，来选择优先级最高的调度类和优先级最高的进程。
在pick_next_task()最开始的部分，如果所有可运行进程数量等于CFS类对应的可运行进程数，表示所有可运行进程都是CFS类的，即所有可运行进程都是普通进程（CFS是普通进程的调度类），就从普通进程中选一个运行。
如果所有可运行进程不都是普通进程，那么就进入for循环，该循环以优先级为序，从最高的优先级类开始遍历每一个调度类。每一个调度类都实现了pick_next_task()函数，该函数返回指向下一个可运行进程的指针。程序会从返回的第一个非NULL值的类中选择下一个可运行进程。

```c
static inline struct task_struct *
pick_next_task(struct rq *rq)
{
    const struct sched_class *class;
    struct task_struct *p;
    
    /*
	  * Optimization: we know that if all tasks are in
	  * the fair class we can call that function directly:
	  */
    if (likely(rq->nr_running == rq->cfs.nr_running)) {
        p = fair_sched_class.pick_next_task(rq);
        if (likely(p)) {
            return p;
    }
    
    class = sched_class_highest;
    for ( ; ; ) {
        p = class->pick_next_task(rq);
        if (p)
            return p;
        
        class = class->next;
    }
}

```

###3.4.睡眠和唤醒
休眠（被阻塞）的进程处于一个特殊的不可置信状态。休眠的一个常见原因就是文件I/O，进程对一个文件执行read()操作，需要从磁盘里读取，或者进程在等待获取键盘输入时。
无论哪种休眠情况，要休眠的进程会吧自己标记成休眠状，从可执行红黑树中移出，放入等待队列，然后调用schedule()选择和执行一个其他进程。
而在唤醒时刚好相反，进程被设置为可执行状态，然后从等待队列移到可执行红黑树中。
进程休眠时有两种状态，TASK_INTERRUPTIBLE和TASK_UNINTERRUPTIBLE。两者唯一的区别是TASK_UNINTERRUPTIBLE会忽略信号，而处于TASK_INTERRUPTIBLE的进程如果接收到一个信号，会被提前唤醒并相应该信号。

####3.4.1.等待队列
等待队列是由等待某些事件发生的进程组成的简单连表。
内核中用wake_queue_head_t来代表等待队列。等待队列可以通过DECLEARE_WAITQUEUE()静态创建，也可以由init_waitqueue_head()动态创建。

```c
DEFINE_WAIT(wait);

add_wait_queue(q, &wait);
while (!condition) {
    prepare_to_wait(&q, &wait, TASK_INTERRUPTITLE);
    if(signal_pending(current))
        /* 处理信号 */
    schedule();   
}
finish_wait(&q, &wait);


void add_wait_queue(wait_queue_head_t *q, wait_queue_t *wait)
{
	unsigned long flags;

	wait->flags &= ~WQ_FLAG_EXCLUSIVE;
	spin_lock_irqsave(&q->lock, flags);
	__add_wait_queue(q, wait);
	spin_unlock_irqrestore(&q->lock, flags);
}
```
一个进程将自己加入到一个等待队列中的步骤：
>* 调用DEFINE_WAIT()创建一个等待队列的项目；
>* 调用add_wait_queue()把自己加入到队列中。该队列会在进程等待的条件满足时唤醒它。唤醒事件的发生在代码的其他地方，发生对等待队列执行wake_up()操作；
>* 调用prepare_to_wait()方法将进程的状态变更为TASK_INTERRUPTIBLE或TASK_UNINTERRUPTIBLE。如果有必要的话会将进程加到等待队列，在接下来的循环遍历可能会用到；
>* 如果状态被设置为TASK_INTERRUPTIBLE，则信号唤醒进程。这就是所谓的伪唤醒（不是因为事件发生的唤醒），因此要检查并处理信号；
>* 进程被唤醒的时候，会再次检查条件，如果条件为真就退出循环，否则就再次调用schedule()并一直重复这步操作；
>* 当条件满足后，进程将自己设置为TASK_RUNNING并调用finish_wait()方法把自己移出等待队列。

如果在进程开始休眠前就满足了唤醒的条件，则进程会退出循环而不会进入休眠状态。

inotify_read()，负责从通知文件描述符中获取信息，其实现是等待队列的一个典型用法。实现的过程遵循上述的模式，但是它的条件检查是放在while的循环中而不是放在条件判断中，这是因为有时可能唤醒的条件会比较多。

```c
# fs/notify/inotify/inotify_user.c
static ssize_t inotify_read(strcut file *file, char __user *buf, 
                            size_t count, loff_t *pos)
{
    struct fsnotify_group *group;
    struct fsnotify_event *kevent;
    char __user *start;
    int ret;
    DEFINE_WAIT(wait);  // 定义并初始化一个等待队列
    
    start = buf;
    group = file->private_data;
    
    while (1) {
        prepare_to_wait(&group->notification_waitq, &wait, TASK_INTERRUPTIBLE);
        
        mutex_lock(&group->notification_mutex);
        kevent = get_one_event(group, count);
        mutex_unlock(&group->notification_mutex);
        
        if (kevent) {
            ret = PTR_ERR(kevent);
            if (IS_ERR(kevent))
                break;
            ret = copy_event_to_user(group, kevent, buf);
            fsnotify_put_event(kevent);
            if (ret < 0) 
                break;
            buf += ret;
            count -= ret;
            continue;
        }
        
        ret = -EAGAIN;
        if (file->f_flags & O_NONBLOCK)
            break;
        ret = -EINTR;
        if (signal_pending(current))
            break;
        
        if (start != buf)
            break;
            
        schedule();
    }
    finish_wait(&group->notification_waitq, &wait);
    
    if (start != buf && ret != -EFAULT)
        ret = buf - start;
    return ret;
}
```

####3.4.2.唤醒
唤醒操作通过函数`wake_up()`进行，该函数会唤醒指定的等待队列上的所有进程。它调用`try_wake_up()`函数，该函数负责将进程设置`TASK_RUNNING`，调用`enqueue_task()`将进程放进红黑树。如果被唤醒的进程优先级比当前正在执行的进程的优先级高，还要设置`need_resched`标识。通常哪段代码促使等待条件达成，它就要负责随后调用`wake_up()`函数。


##4.抢占和上下文切换
上下文切换，即从一个可执行进程切换到另一个可执行进程，由定义在kernel/sched.c中的context_switch()函数负责处理。当准备执行一个新的进程时，schedule()会调用context_switch()函数，该函数完成以下工作：
>* 调用声明在<asm/mmu_context.h>中的switch_mm()，该函数负责切换虚拟内存，把虚拟内存从上一个进程映射切换到新进程中；
>* 调用声明在<asm/system.h>中的switch_to()，该函数负责切换处理状态，即从上一个进程的处理器状态切换到新进程的处理器状态。这其中包括保存、恢复栈信息和寄存器信息，还有其他任何与体系结构相关的状态信息，这些信息都将以每个进程为对象进行管理和保存。

内核中提供了一个need_resched标志来表明是否需要重新执行一次调度，如果没有这个标志来告诉内核何时调用schedule()而是仅靠用户程序代码显式调用，这样可能会使得一个进程永远地执行下去。内核如果检查到该标志被设置，会调用schedule()来切换一个新的进程。
当某个进程被抢占时，scheduler_tick()就设置need_resched标志；当一个优先级高的进程进入可执行状态时，try_to_wake_up()会设置need_resched标志。
在返回用户空间以及从中断返回的时候，内核也会检查need_resched标志，如果已被设置，内核会在继续执行之前调用调度程序。
除了全局变量中有一个need_resched标志外，每一个进程的task_struct结构中也会冗余一位，因为进程访问进程描述符内的变量要比访问全局变量快。

###4.1.用户抢占
在内核即将返回用户空间的时候（要去执行用户程序的时候），检查need_resched标志，来决定是否调用schedule()以及发生用户抢占。如果在这一次新的调度中有优先级更高的进程，那么内核将会去执行该进程，即发生了用户抢占。如果need_resched没有被设置或者没有优先级更高的进程，那么会继续执行原来的进程。
用户抢占发生的情况：
>* 从系统调返回用户空间时；
>* 从中断处理程序返回用户空间时。

###4.2.内核抢占
大部分Unix变体或者其他大部分操作系统中不支持内核抢占，即内核代码可以一直执行，直到它完成为止。也就是在调度程序无法在一个内核级的任务正在执行时被调用进行重新调度。
Linux系统中完整地支持内核抢占，只要重新调度是安全的，内核就可以在任何时间抢占再整执行的任务。
只要没有持有锁，内核就可以进行抢占。锁是非抢占区域的标志。
为了支持内核抢占，在每个进程的thread_info中加入了preempt_count计数器。该计数器初始值为0，每当进程使用锁的时候数值加1，释放锁的时候数值减1。
当从中断返回内核空间的时候，会检查need_resched和preempt_count的值，如果need_resched被设置以及preempt_count为0时，将执行一次schedule()调度函数；如果preempt_count不为0，说明当前程序持有锁，所以抢占是不安全的。
如果内核中的进程被阻塞了，或者内核的进程显式地调用了schedule()，内核抢占也会显式地发生。
内核抢占发生的情况：
>* 中断处理程序正在执行，且返回内核空间之前；
>* 内核代码再一次具有可抢占性的时候；
>* 如果内核中的任务显式地调用schedule()；
>* 如果内核中的任务阻塞（这同样也会导致调用schedule()）

##5.实时调度策略
Linux提供了SCHED_FIFO和SCHED_RR两种实时调度策略，而普通的、非实时的调度策略是SCHED_NORMAL。
这些实时策略并不被完全公平调度器来管理，而是被一个特殊的实时调度器管理，具体的实现定义在kernel/sched_rt.c中。
###5.1.SCHED_FIFO
简单的先进先出算法，不适用时间片。处于SCHED_FIFO状态的进程会比任何SCHED_NORMAL级的进程都先得到调度，并且会一直执行下去（因为没时间片限制），直到它自己受到阻塞或者显式地释放处理器为止。
只有更高优先级的SCHED_FIFO或者SCHED_RR任务才能抢占SCHED_FIFO任务。如果有两个或者更多的同优先级的SCHED_FIFO进程，它们会轮流执行，但只有在它们自己愿意让出处理器时才会推出。

###5.2.SCHED_RR
SCHED_RR和SCHED_FIFO大体相同，但是SCHED_RR是带有时间片的SCHED_FIFO。

###5.3.软实时与硬实时
软实时：内核调度进程会尽量使进程在它的限定时间到来前运行，但内核不保证总能满足这些进程要求。
硬实时：保证在一定条件下可以满足任何调度的要求。

##6.与调度相关的系统调用

| 系统调用 | 描述 |
|----|----|
|nice()|设置进程的nice值|
|sched_setscheduler()|设置进程调度策略|
|sched_getscheduler()|获取进程的调度策略|
|sched_setparam()|设置进程实时优先级|
|sched_getparam()|获取进程的实时优先级|
|sched_get_priority_max()|获取实时优先级的最大值|
|sched_get_priority_min()|获取实时优先级的最小值|
|sched_rr_get_interval()|获取进程的时间片值|
|sched_setaffinity()|设置进程的处理器的亲和力|
|sched_getaffinity()|获取进程的处理器的亲和力|
|sched_yield()|暂时让出处理器|






