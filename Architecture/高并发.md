# 高并发

##代码
先从代码上优化，做业务拆分，做任务存储等；


##数据
n+1问题
    join的话在代码层面看似比较高效，但是场景过于特定，且不利于mysql内部的查询缓存
    分开使用orm的方式取，数据颗粒度较小，有利于缓存，也可将orm添加到缓存层


###高并发读
优化sql语句，通过添加合适的索引

加入cache，高并发时就增加cache的从机
强一致性时优化主从同步的速度，用多线程同步入库来增加主从同步速度

###高并发写
通过队列来异步写入；
如果数据要求事务性较高，拆到不同的库/不同的机子/不同的实例来硬扛
也就是不同的业务，根据哈希算法写入不同机子

拆表拆库不宜过早，容易导致系统太复杂


数据库集群
Mysql Proxy
读写分离，在读写比例较高时才能用，否则写的比例过高，此时由于写的语句优先级高，会影响读的语句，所以会导致慢查询


数据库分表
垂直分表，把主数据放在一个表，其他数据分到另一个表
水平分表，根据某个字段的值把数据分到表结构相同的不同的表。


缓存层
    更新策略，主动或被动
        主动过期，数据有修改时，添加一个回调去更新缓存
        被动过期
    
    分布式缓存

keepalived做热备redis服务器代理

增删改都是直接操作mysql变更都在MySQL（这里高并发的问题是用分库分表加外层的负载均衡） 所以我们的方向是读取binlog然后分析 ，利用消息推送到某服务器A，再进行分析，然后更新各台redis，消息推送工具用的是rabbitMQ，可设定某表的变更推送(分三类update insert delate 包含变更前后的数据)，这里有个问题是：mysql数据操作太频繁产生的推送可能会很多，所以分析处理脚本处理速度一定要跟得上（我用Python写，前期多线程（坑），后来改成多进程），还有一个问题是，对于mysql-redis的数据关系映射设定不要太复杂，一表对一表就行，数据组合交给业务层做，这样分析处理脚本不会太多负担，处理速度更快，而且操作redis也更简单，redis每个对应mysql数据表的可使用多端口多实例，redis是单线程而且这样对于redis的主从和负载均衡有利，

题外话：对于服务器A 可以再给其它服务做一个数据表增量变更数据获取接口，利用数据纬度，获取时间段的变更数据。

追加，对于订单类部分，都是完全使用mysql，这个做好数据服务器，DB，table，分区，的拆分就好了，看并发请求越多拆分越多。



##服务器
静态资源缓存

资源服务器分离

负载均衡

